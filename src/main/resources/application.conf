http {
  host = "localhost"
  port = "8888"
}

akka {
  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  # Log level used by the configured loggers (see "loggers") as soon
  # as they have been started; before that, see "stdout-loglevel"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "DEBUG"

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = "INFO"

  # Filter of log events that is used by the LoggingAdapter before
  # publishToKafka log events to the eventStream.
  logging-filter = "akka.event.DefaultLoggingFilter"

  #Dead-letter logging settings
  #log-dead-letters = 1
  #log-dead-letters-during-shutdown = off

  kafka {
    consumer {
      bootstrap-servers = "localhost:9092"
      groupId = "group1"
      commit = false
      topics = "topic1"
      start-from = "earliest"
      fetch.bytes = 262144
      message.count = 10

      # Tuning property of scheduled polls.
      poll-interval = 50ms

      # Tuning property of the `KafkaConsumer.poll` parameter.
      # Note that non-zero value means that blocking of the thread that
      # is executing the stage will be blocked.
      poll-timeout = 50ms

      # The stage will be await outstanding offset commit requests before
      # shutting down, but if that takes longer than this timeout it will
      # stop forcefully.
      stop-timeout = 30s

      # If offset commit requests are not completed within this timeout
      # the returned Future is completed `TimeoutException`.
      close-timeout = 20s

      # If offset commit requests are not completed within this timeout
      # the returned Future is completed `TimeoutException`.
      commit-timeout = 15s

      # If commits take longer than this time a warning is logged
      #commit-time-warning = 1s

      # If the KafkaConsumer can't connect to the broker the poll will be
      # aborted after this timeout. The KafkaConsumerActor will throw
      # org.apache.kafka.common.errors.WakeupException, which can be handled
      # with Actor supervision strategy.
      wakeup-timeout = 10s

      # After exceeding maxinum wakeups the consumer will stop and the stage will fail.
      max-wakeups = 10

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the KafkaConsumerActor. Some blocking may occur.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # Properties defined by org.apache.kafka.clients.consumers.ConsumerConfig
      # can be defined in this configuration section.
      kafka-clients {
        # Disable auto-commit by default
        enable.auto.commit = false
        #auto.commit.interval.ms = 10000
      }
    }

    producer {
      bootstrap-servers = "localhost:9092"
      public-topic = "topic1"

      # Tuning parameter of how many sends that can run in parallel.
      parallelism = 100

      # How long to wait for `KafkaProducer.close`
      close-timeout = 60s

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the producers stages. Some blocking may occur.
      # When this value is empty, the dispatcher configured for the stream
      # will be used.
      use-dispatcher = "akka.kafka.default-dispatcher"

      request.required.acks = "1"

      num.partitions = "5"

      compression.type = "none"
      batch.size = 65536
      linger.ms = 200
      buffer.memory = 33554432

      # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
      # can be defined in this configuration section.
      kafka-clients {
      }
    }
  }

  output {
    logger {
      level = "INFO"
    }
    file {
      name = "output/kafka-output.txt"
    }
  }

}